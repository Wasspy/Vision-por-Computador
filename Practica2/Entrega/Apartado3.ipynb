{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Apartado3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vpcYe5cBmsuQ","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","\"\"\"EsquemaParte3.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1Ge_Pw-txgQ1PRJTdJPioBOl02yILeVuf\n","\"\"\"\n","\n","#########################################################################\n","################### OBTENER LA BASE DE DATOS ############################\n","#########################################################################\n","\n","# Descargar las imágenes de http://www.vision.caltech.edu/visipedia/CUB-200.html\n","# Descomprimir el fichero.\n","# Descargar también el fichero list.tar.gz, descomprimirlo y guardar los ficheros\n","# test.txt y train.txt dentro de la carpeta de imágenes anterior. Estos \n","# dos ficheros contienen la partición en train y test del conjunto de datos.\n","\n","##### EN CASO DE USAR COLABORATORY\n","# Sube tanto las imágenes como los ficheros text.txt y train.txt a tu drive.\n","# Después, ejecuta esta celda y sigue las instrucciones para montar \n","# tu drive en colaboratory.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!unzip /content/drive/My\\ Drive/VC/P2/images.zip -d /content/\n","\n","#########################################################################\n","################ CARGAR LAS LIBRERÍAS NECESARIAS ########################\n","#########################################################################\n","\n","# Terminar de rellenar este bloque con lo que vaya haciendo falta\n","\n","# Importar librerías necesarias\n","import numpy as np\n","import matplotlib.pyplot as plt \n","import keras\n","import keras.utils as np_utils\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Flatten, Activation, Input\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.preprocessing.image import load_img, img_to_array \n","\n","\n","# Importar el optimizador a usar\n","from keras.optimizers import SGD\n","\n","# Importar modelos y capas específicas que se van a usar\n","\n","# Preprocesamiento de datos\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# Importar el modelo ResNet50 y su respectiva función de preprocesamiento,\n","# que es necesario pasarle a las imágenes para usar este modelo\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications.resnet50 import preprocess_input\n","\n","\n","#########################################################################\n","################## FUNCIÓN PARA LEER LAS IMÁGENES #######################\n","#########################################################################\n","\n","# Dado un fichero train.txt o test.txt y el path donde se encuentran los\n","# ficheros y las imágenes, esta función lee las imágenes\n","# especificadas en ese fichero y devuelve las imágenes en un vector y \n","# sus clases en otro.\n","\n","def leerImagenes(vec_imagenes, path):\n","  clases = np.array([img.split('/')[0] for img in vec_imagenes])\n","  imagenes = np.array([img_to_array(load_img(path + \"/\" + img, \n","                                             target_size = (224, 224))) \n","                       for img in vec_imagenes])\n","  return imagenes, clases\n","\n","#########################################################################\n","############# FUNCIÓN PARA CARGAR EL CONJUNTO DE DATOS ##################\n","#########################################################################\n","\n","# Usando la función anterior, y dado el path donde se encuentran las\n","# imágenes y los archivos \"train.txt\" y \"test.txt\", devuelve las \n","# imágenes y las clases de train y test para usarlas con keras\n","# directamente.\n","\n","def cargarDatos(path):\n","\n","  # Cargamos los ficheros\n","  train_images = np.loadtxt(path + \"/train.txt\", dtype = str)\n","  test_images = np.loadtxt(path + \"/test.txt\", dtype = str)\n","  \n","  # Leemos las imágenes con la función anterior\n","  train, train_clases = leerImagenes(train_images, path)\n","  test, test_clases = leerImagenes(test_images, path)\n","  \n","  # Pasamos los vectores de las clases a matrices \n","  # Para ello, primero pasamos las clases a números enteros\n","  clases_posibles = np.unique(np.copy(train_clases))\n","  for i in range(len(clases_posibles)):\n","    train_clases[train_clases == clases_posibles[i]] = i\n","    test_clases[test_clases == clases_posibles[i]] = i\n","\n","  # Después, usamos la función to_categorical()\n","  train_clases = np_utils.to_categorical(train_clases, 200)\n","  test_clases = np_utils.to_categorical(test_clases, 200)\n","  \n","  # Barajar los datos\n","  train_perm = np.random.permutation(len(train))\n","  train = train[train_perm]\n","  train_clases = train_clases[train_perm]\n","\n","  test_perm = np.random.permutation(len(test))\n","  test = test[test_perm]\n","  test_clases = test_clases[test_perm]\n","  \n","  return train, train_clases, test, test_clases\n","\n","#########################################################################\n","######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########\n","#########################################################################\n","\n","# Esta función devuelve el accuracy de un modelo, definido como el \n","# porcentaje de etiquetas bien predichas frente al total de etiquetas.\n","# Como parámetros es necesario pasarle el vector de etiquetas verdaderas\n","# y el vector de etiquetas predichas, en el formato de keras (matrices\n","# donde cada etiqueta ocupa una fila, con un 1 en la posición de la clase\n","# a la que pertenece y 0 en las demás).\n","\n","def calcularAccuracy(labels, preds):\n","  labels = np.argmax(labels, axis = 1)\n","  preds = np.argmax(preds, axis = 1)\n","  \n","  accuracy = sum(labels == preds)/len(labels)\n","  \n","  return accuracy\n","\n","#########################################################################\n","## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###\n","#########################################################################\n","\n","# Esta función pinta dos gráficas, una con la evolución de la función\n","# de pérdida en el conjunto de train y en el de validación, y otra\n","# con la evolución del accuracy en el conjunto de train y en el de\n","# validación. Es necesario pasarle como parámetro el historial\n","# del entrenamiento del modelo (lo que devuelven las funciones\n","# fit() y fit_generator()).\n","\n","def mostrarEvolucion(hist):\n","\n","  loss = hist.history['loss']\n","  val_loss = hist.history['val_loss']\n","  plt.plot(loss)\n","  plt.plot(val_loss)\n","  plt.legend(['Training loss', 'Validation loss'])\n","  plt.show()\n","\n","  acc = hist.history['acc']\n","  val_acc = hist.history['val_acc']\n","  plt.plot(acc)\n","  plt.plot(val_acc)\n","  plt.legend(['Training accuracy', 'Validation accuracy'])\n","  plt.show()\n","\n","################################################################################\n"," ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ##  ## \n","################################################################################ \n","\n","## Usar ResNet50 preentrenada en ImageNet como un extractor de características\n","def ExtractorCaracteristicas (x_train, y_train, x_test, y_test):\n","\n","    print(\"Usar ResNet50 preentrenada en ImageNet como un extractor de características\")\n","\n","    # Preprocesamiento de los conjuntos de datos de train y test\n","    x_train = preprocess_input(x_train)\n","    x_test = preprocess_input(x_test)\n","\n","    # Modelo ResNet50 (preentrenado en ImageNet y sin la última capa).\n","    resnet50 = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n","\n","    # Extraer las características las imágenes con el modelo anterior.\n","    train_pred = resnet50.predict(x_train, verbose=1)\n","    test_pred = resnet50.predict(x_test, verbose=1)\n","\n","    # Las características extraídas en el paso anterior van a ser la entrada de\n","    # un pequeño modelo de dos capas Fully Conected, donde la última será la que \n","    # nos clasifique las clases de Caltech-UCSD (200 clases). De esta forma, es \n","    # como si hubiéramos fijado todos los parámetros de ResNet50 y estuviésemos\n","    # entrenando únicamente las capas añadidas. Definir dicho modelo.\n","\n","    model = Sequential()\n","    model.add(Dense (2048, activation='linear', input_shape=(2048,)))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","\n","    model.add(Dense (200, activation='linear'))\n","    model.add(BatchNormalization())\n","\n","    model.add(Activation('softmax')) # Transformar la salida de las neuronas\n","\n","    model.summary()\n","\n","    print()\n","    \n","    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=SGD(), \n","                  metrics=['accuracy'])\n","\n","    # Entrenamiento del modelo\n","    hist = model.fit(train_pred, y_train, batch_size=32, verbose=1, epochs=20, \n","                     validation_split=0.2)\n","\n","    # Se prueba el modelo con el conjunto test\n","    predictions = model.predict(test_pred, verbose=1)\n","\n","    # Se muestran los resultados\n","    acc = calcularAccuracy(y_test, predictions)\n","\n","    mostrarEvolucion(hist)\n","\n","    print(\"\\nAccuracy: %f %%\" % (acc*100))\n","\n","# Reentrenar ResNet50 (fine tunning)\n","def Reentrenar(x_train, y_train, x_test, y_test):\n","\n","    print(\"Reentrenar ResNet50 (fine tunning)\")\n","\n","    # Preprocesamiento de los conjuntos de datos de train y test\n","    x_train = preprocess_input(x_train)\n","    x_test = preprocess_input(x_test)\n","\n","    # Modelo ResNet50 (preentrenado en ImageNet y sin la última capa).\n","    resnet50 = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n","\n","    # Modelo ResNet50 con nueva capa totalmente conectada\n","    x = resnet50.output\n","    x = Dense(2048, activation='relu')(x)\n","    x = BatchNormalization()(x)\n","    last = Dense(200, activation='softmax')(x)\n","    model = Model(inputs=resnet50.input, outputs=last)\n","\n","    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=SGD(), \n","                  metrics=['accuracy'])\n","\n","    # Entrenamiento del modelo\n","    hist = model.fit(x_train, y_train, batch_size=32, verbose=1, epochs=14, \n","                      validation_split=0.2)\n","\n","    # Se prueba el modelo con el conjunto test\n","    predictions = model.predict(x_test, verbose=1)\n","\n","    # Se muestran los resultados\n","    acc = calcularAccuracy(y_test, predictions)\n","\n","    mostrarEvolucion(hist)\n","\n","    print(\"\\nAccuracy: %f %%\" % (acc*100))\n","\n","#########################################################################\n","################################# MAIN ##################################\n","#########################################################################\n","def main ():\n","\n","    # Se cargan las imagenes y se dividen en conjuntos de train y test\n","    x_train, y_train, x_test, y_test = cargarDatos('/content')\n","\n","    # Usar ResNet50 preentrenada en ImageNet como un extractor de características \n","    ExtractorCaracteristicas (x_train, y_train, x_test, y_test)\n","\n","    input('\\nPulsar \\'enter\\' para continuar con el apartado 2:')\n","\n","    # Reentrenar ResNet50 (fine tunning)\n","    Reentrenar(x_train, y_train, x_test, y_test)\n","\n","#########################################################################\n","#########################################################################\n","    \n","# Se llama al programa principal para que ejecute el programa\n","if __name__ == '__main__':\n","\n","    main()\n"],"execution_count":0,"outputs":[]}]}