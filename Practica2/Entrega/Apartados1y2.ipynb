{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Apartados1y2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"phMc8rom1AFR","colab_type":"code","colab":{}},"source":["# -*- coding: utf-8 -*-\n","#########################################################################\n","############ CARGAR LAS LIBRERÍAS NECESARIAS ############################\n","#########################################################################\n","\n","import numpy as np\n","import keras\n","import matplotlib.pyplot as plt \n","import keras.utils as np_utils\n","\n","from keras.callbacks import EarlyStopping\n","\n","# Modelos y capas que se van a usar\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.layers import Dense, Flatten, Activation\n","\n","# Preprocesamiento de datos\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# Optimizador que se va a usar\n","from keras.optimizers import SGD \n","\n","# Conjunto de datos\n","from keras.datasets import cifar100\n","\n","# Se fija la semilla de números aleatorios\n","from numpy.random import seed\n","\n","seed(15)\n","\n","#########################################################################\n","######## FUNCIÓN PARA CARGAR Y MODIFICAR EL CONJUNTO DE DATOS ###########\n","#########################################################################\n","\n","# Esta función solo se le llama una vez. Devuelve 4 vectores conteniendo:\n","#    -> Las imágenes de entrenamiento\n","#    -> Las clases de las imágenes de entrenamiento\n","#    -> Las imágenes del conjunto de test\n","#    -> Las clases del conunto de test\n","# (En ese orden)\n","\n","def cargarImagenes():\n","    \n","    # Cargamos Cifrar100 \n","    # Cada imagen tienen tamaño (32,32,3)\n","    # Nos quedamos con 25 clases\n","    \n","    (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n","    \n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    \n","    # Se normaliza entre 0 y 1\n","    x_train /= 255\n","    x_test /= 255\n","    \n","    # Nos quedamos con 25 clases\n","    train_idx = np.isin(y_train, np.arange(25))\n","    train_idx = np.reshape(train_idx, -1)\n","    \n","    # Guardamos los conjuntos de esas 25 clases\n","    x_train = x_train[train_idx]\n","    y_train = y_train[train_idx]\n","    \n","    # Nos quedamos con 25 clases\n","    test_idx = np.isin(y_test, np.arange(25))\n","    test_idx = np.reshape(test_idx, -1)\n","    \n","    # Guardamos los conjuntos de esas 25 clases\n","    x_test = x_test[test_idx]\n","    y_test = y_test[test_idx]\n","    \n","    # Transformamos los vectores de clases en matrices. \n","    # Cada componente se convierte en un vecor de ceros con un uno en el \n","    # componente correspondiente a la clase a la que pertenece la imagen. Este \n","    # paso es NECESARIO para la clasificación multiclase en keras. \n","    \n","    y_train = np_utils.to_categorical(y_train, 25)\n","    y_test = np_utils.to_categorical(y_test, 25)\n","    \n","    return x_train, y_train, x_test, y_test\n","\n","#########################################################################\n","######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########\n","#########################################################################\n","\n","# Esta función devuelve el accuracy de un modelo, definido como el porcentaje \n","# de etiquetas bien predichas frente al total de etiquetas. Como parámetros es\n","# necesario pasarle el vector de etiquetas verdaderas y el vector de etiquetas \n","# predichas, en el formato de keras (matrices donde cada etiqueta ocupa una \n","# fila, con un 1 en la posición de la clase a la que pertenece y 0 en las demás)\n","\n","def calcularAccuracy(labels, preds):\n","    \n","    labels = np.argmax(labels, axis=1)\n","    preds = np.argmax(preds, axis=1)\n","    \n","    accuracy = sum(labels == preds)/len(labels)\n","    \n","    return accuracy\n","\n","#########################################################################\n","## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###\n","#########################################################################\n","\n","# Esta función pinta dos gráficas, una con la evolución de la función de \n","# pérdida en el conjunto de train y en el de validación, y otra con la \n","# evolución del accuracy en el conjunto de train y el de validación. Es \n","# necesario pasarle como parámetro el historial del entrenamiento del modelo\n","# (lo que devuelven las funciones fit() y fit_generator())\n","\n","def mostrarEvolucion(hist):\n","    \n","    loss = hist.history['loss']\n","    \n","    val_loss = hist.history['val_loss']\n","    \n","    plt.plot(loss)\n","    plt.plot(val_loss)\n","    plt.legend(['Training loss', 'Validation loss'])\n","    plt.show()\n","    \n","    acc = hist.history['acc']\n","    \n","    val_acc = hist.history['val_acc']\n","    \n","    plt.plot(acc)\n","    plt.plot(val_acc)\n","    plt.legend(['Training accuracy', 'Validation accuracy'])\n","    plt.show()\n","\n","#########################################################################\n","################## DEFINICIÓN DEL MODELO BASENET ########################\n","#########################################################################\n","\n","def modeloBase (x_train, y_train, x_test, y_test):\n","\n","    # Definición del modelo\n","    model = Sequential()\n","\n","    model.add(Conv2D(6, (5,5), activation='relu', input_shape=(32,32,3)))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","    model.add(Conv2D(16, (5,5), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","    model.add(Flatten())    # Aplana la matriz\n","\n","    model.add(Dense(50, activation='linear'))     # 50 es la dimensión de salida\n","    model.add(Activation('relu'))\n","\n","    model.add(Dense(25, activation='linear'))\n","    model.add(Activation('softmax'))              # Transformar la salida de las neuronas \n","                                                  # en la probabilidad de pertenecer a cada clase\n","    model.summary()\n","\n","    print()\n","\n","    ###############################################################\n","    ##### DEFINICIÓN DEL OPTIMIZADOR Y COMPILACIÓN DEL MODELO #####\n","    ###############################################################\n","\n","    model.compile(loss=keras.losses.categorical_crossentropy, \n","                  optimizer=SGD(), metrics=['accuracy'])\n","\n","    # Una vez tenemos el modelo base, y antes de entrenar, vamos a \n","    # guardar los pesos aleatorios con los que empieza la red, para \n","    # poder reestablecerlos después y comparar resultados entre no \n","    # usar mejoras y sí usarlas.\n","    weights = model.get_weights()\n","\n","    ###############################################################\n","    ################## ENTRENAMIENTO DEL MODELO ###################\n","    ###############################################################\n","\n","    historial = model.fit(x_train, y_train, batch_size=32, epochs=15, verbose=1,#verbose=1,\n","                          validation_split=0.2)\n","\n","    # 20 - 25 épocas\n","    # 32 de batch\n","\n","    ###############################################################\n","    ############ PREDICCIÓN SOBRE EL CONJUNTO DE TEST #############\n","    ###############################################################\n","\n","    predictions = model.predict(x_test)\n","\n","    accuracy = calcularAccuracy(y_test, predictions)\n","\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","\n","    print(\"\\n Modelo basico:\")   \n","    print(' -> Test accuracy: %f %%' % (score[1] * 100))\n","\n","    mostrarEvolucion(historial)\n","\n","    return score[0], score[1]\n","\n","#########################################################################\n","########################## MEJORA DEL MODELO ############################\n","#########################################################################\n","\n","def modeloMejorado(x_train, y_train, x_test, y_test):\n","\n","    # Normalizacion + Aumento de los datos\n","    datagen_train = ImageDataGenerator(featurewise_center=True,\n","                                       featurewise_std_normalization=True,\n","                                       validation_split=0.2,\n","                                       horizontal_flip=True,\n","                                       zoom_range=0.2)\n","\n","    datagen_test = ImageDataGenerator(featurewise_center=True,\n","                                      featurewise_std_normalization=True)\n","\n","    datagen_train.fit(x_train)\n","    datagen_test.fit(x_test)\n","\n","    # Definición del modelo\n","    model = Sequential()\n","\n","    model.add(Conv2D(6, (5,5), activation='relu', input_shape=(32,32,3)))\n","    model.add(BatchNormalization())\n","\n","    model.add(Conv2D(56, (5,5), activation='relu'))\n","    model.add(BatchNormalization())\n","\n","    model.add(Conv2D(106, (5,5), activation='relu'))\n","    model.add(BatchNormalization())\n","\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","    model.add(Flatten())                          # Aplana la matriz\n","\n","    model.add(Dense(50, activation='linear'))     # 50 es la dimensión de salida\n","    model.add(Activation('relu'))\n","    model.add(BatchNormalization())\n","\n","    model.add(Dense(25, activation='linear'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('softmax'))              # Transformar la salida de las neuronas \n","                                                  # en la probabilidad de pertenecer a cada clase\n","    model.summary()\n","\n","    print()\n","\n","    # Se compila el modelo\n","    model.compile(loss=keras.losses.categorical_crossentropy, \n","                  optimizer=SGD(), metrics=['accuracy'])\n","\n","    # Entrenamiento del modelo\n","    #es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\n","    hist = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=32, \n","                                                  subset='training'),  \n","                               verbose=1, epochs=20, \n","                               validation_data=datagen_train.flow(x_train, y_train, \n","                                                                  batch_size=32,\n","                                                                  subset='validation'))\n","                              #callbacks=[es])\n","\n","    # Predicción en el conjunto test y resultados\n","    score = model.evaluate(datagen_test.flow(x_test, y_test), verbose=0)\n","\n","    predictions = model.predict(datagen_test.flow(x_test))\n","\n","    print(\"\\n Modelo mejorado:\")   \n","    print(' -> Test accuracy: %f %%' % (score[1] * 100))\n","\n","    mostrarEvolucion(hist)\n","\n","    return score[0], score[1]\n","\n","#########################################################################\n","################################# MAIN ##################################\n","#########################################################################\n","def main ():\n","\n","    # Se cargan las imagenes y se dividen en conjuntos de train y test\n","    x_train, y_train, x_test, y_test = cargarImagenes()\n","\n","    # Modelo basico (Apartado 1)\n","    lossb, accb = modeloBase(x_train, y_train, x_test, y_test)\n","\n","    input('\\nPulsar \\'enter\\' para continuar con el apartado 2:')\n","\n","    # Modelo mejorado (Apartado 2)\n","    lossm, accm = modeloMejorado(x_train, y_train, x_test, y_test)\n","\n","\n","#########################################################################\n","#########################################################################\n","    \n","# Se llama al programa principal para que ejecute el programa\n","if __name__ == '__main__':\n","\n","    main()\n"],"execution_count":0,"outputs":[]}]}